{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVbIHaijT5op",
        "outputId": "6b0e4432-f76c-4cb6-b786-ed6ba302f752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m87.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Install Gradio\n",
        "!pip install gradio --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hlhS8FYSKs2"
      },
      "source": [
        "**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oq0149gORHay"
      },
      "outputs": [],
      "source": [
        "from PIL import Image, ImageTk\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oav5O2lBeIz_"
      },
      "source": [
        "**Mounting Drive & Defining Paths**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48E1_nIfSr6z",
        "outputId": "af31f575-bc74-4f04-f68b-63b677be3eca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_k0Md_DSGw9"
      },
      "source": [
        "**Load The Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OlnJY4FNSHIT"
      },
      "outputs": [],
      "source": [
        "# List of model paths\n",
        "model_paths = [\n",
        "    \"/content/drive/MyDrive/LungCancer_CNN_model_v2.h5\",\n",
        "    \"/content/drive/MyDrive/LungCancer_VGG16_model_v2.h5\",\n",
        "    \"/content/drive/MyDrive/LungCancer_InceptionV3_model_v2.h5\",\n",
        "    \"/content/drive/MyDrive/LungCancer_ResNet50_model_v2.h5\",\n",
        "    \"/content/drive/MyDrive/LungCancer_CNN_model_v3.h5\"\n",
        "]\n",
        "\n",
        "# Dictionary to store model paths and their test accuracies\n",
        "models_info = {\n",
        "    'CNN Model V1': {'path': model_paths[0]},\n",
        "    'VGG16 Model (Best Performer)': {'path': model_paths[1]},\n",
        "    'InceptionV3 Model': {'path': model_paths[2]},\n",
        "    'ResNet50 Model': {'path': model_paths[3]},\n",
        "    'CNN Model V2': {'path': model_paths[4]}\n",
        "}\n",
        "\n",
        "# Class labels (update based on your dataset)\n",
        "class_labels = {0: \"Adenocarcinoma\", 1: \"Benign\", 2: \"Squamous Cell Carcinoma\"}\n",
        "\n",
        "# Global variable to store the loaded model\n",
        "loaded_model = None\n",
        "\n",
        "def choose_and_load_model(model_name):\n",
        "    global loaded_model\n",
        "    model_path = models_info[model_name]['path']\n",
        "\n",
        "    # Check if the model file exists\n",
        "    if not os.path.exists(model_path):\n",
        "        return f\"Model file not found at {model_path}\"\n",
        "\n",
        "    # Load the selected model\n",
        "    loaded_model = load_model(model_path)\n",
        "    return f\"Loaded {model_name} from {model_path}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDDZATI7SWrZ"
      },
      "source": [
        "**Make The GUI**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JmkJMu9ZQ_kg"
      },
      "outputs": [],
      "source": [
        "def predict_lung_cancer(img):\n",
        "    global loaded_model\n",
        "    if loaded_model is None:\n",
        "        return \"No model loaded. Please select a model first.\"\n",
        "\n",
        "    # Preprocess the image\n",
        "    img = img.resize((150, 150))  # Resize image to 150x150\n",
        "    img_array = np.array(img) / 255.0  # Rescale pixel values\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Predict using the model\n",
        "    predictions = loaded_model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    confidence = np.max(predictions)\n",
        "\n",
        "    # Get class label\n",
        "    predicted_class = class_labels.get(predicted_class_index, \"Unknown\")\n",
        "    return f\"Prediction: {predicted_class} | Confidence: {confidence:.2f}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-WQ_XN8ISdvS"
      },
      "outputs": [],
      "source": [
        "# Create a Gradio interface\n",
        "def gradio_interface():\n",
        "    model_names = list(models_info.keys())\n",
        "    dropdown = gr.Dropdown(choices=model_names, label=\"Select Model\")\n",
        "    image_input = gr.Image(type=\"pil\", label=\"Upload Image\")\n",
        "    output = gr.Textbox(label=\"Output\")\n",
        "\n",
        "    def combined_function(model_name, img):\n",
        "        load_message = choose_and_load_model(model_name)\n",
        "        prediction_message = predict_lung_cancer(img)\n",
        "        return f\"{load_message}\\n{prediction_message}\"\n",
        "\n",
        "    gr.Interface(\n",
        "        fn=combined_function,\n",
        "        inputs=[dropdown, image_input],\n",
        "        outputs=output\n",
        "    ).launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2f44eMgWOKO"
      },
      "source": [
        "**Launch The App**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Launch the interface\n",
        "gradio_interface()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "LzUYac3DXcx-",
        "outputId": "02c672b8-572d-4479-e15e-2cde43f58f04"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://f798cc2b57f0e10430.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f798cc2b57f0e10430.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}